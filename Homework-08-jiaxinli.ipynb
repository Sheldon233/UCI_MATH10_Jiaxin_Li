{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "### Jiaxin Li 77664780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, please feel free to call the functions in sklean.\n",
    "\n",
    "Basic Requirements:\n",
    "1. load the hand-written digit data, and split train and test datasets (follow the last homework);\n",
    "2. Fit the kNN and random forest model separately on training data, and report the performance on test data -- you don't have to tune the parameters for basic requirements, choosing the parameters as you like;\n",
    "3. Compare the performace with logistic regression;\n",
    "4. Write some comments in the code, OR use markdown paragraphs to indicate what you are doing in the specific step.\n",
    "\n",
    "Optional Task:\n",
    "Using cross-validations to select the parameters when fitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Loading data and split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits   #Import data\n",
    "X,y = load_digits(return_X_y = True)      #Set X to be dataset that contains 1798 samples, and y to be lables for each row in X.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)   #Randomly take out 20% of the dataset as testing data. \n",
    "print(X_train.shape)   \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stpe 2: Fit the kNN and random forest model separately on training data, and report the performance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which class a sample come from by counting the nearist 10 samples, which label appear most times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on determining lable on test dataset is 97.5 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 10)    \n",
    "knn_clf.fit(X_train, y_train)      \n",
    "a=knn_clf.score(X_test,y_test)\n",
    "print(\"the accuracy on determining lable on test dataset is\", a*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " make 1000 decision trees by random picking up 90% of the dataset, and each tree has the maximum depth of 5 in order to avoid overfitting. njobs = -1 means you ask to use all the processors of your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on determining lable on test dataset is 91.94444444444444 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, max_samples = 0.5, max_depth=5, random_state=0, n_jobs = -1)\n",
    "rf_clf.fit(X_train, y_train) # train the \"forest\" on training dataset. fit perimeters\n",
    "b=rf_clf.score(X_test, y_test)  # test on testing datast\n",
    "print(\"the accuracy on determining lable on test dataset is\", b*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stpe 3: Compare with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.38888888888889 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(max_iter=100000)\n",
    "clf.fit(X_train,y_train)   #find the optimal coefficients\n",
    "y_pred=clf.predict(X_test)\n",
    "p=np.sum(y_pred==y_test)*1/len(y_pred)*100  #compare each entry in pred_y and y_test to see how many of them are the same. And then find the accuracy.\n",
    "print(\"accuracy:\", p,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary\n",
    "from the results above we can see the KNN method perform the best with 97.5% accuracy, and Logistic regression the second with 96.389% accuracy. The lowest one is RandomForestClassifier, with accuracy 91.94%. \n",
    "### In general all three ways perform well on preditcting the lable on test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional, using cross validation to determine k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_list = list(range(1,50,10))\n",
    "# creating dataframe of cv scores and test scores -- of course you can also use Numpy array\n",
    "cv_scores = pd.DataFrame()\n",
    "test_scores = pd.Series(dtype = 'float64')\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in k_list:\n",
    "    knn_clf.set_params(n_neighbors=k) # update the object\n",
    "    scores = cross_val_score(knn_clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores[str(k)] = scores\n",
    "    test_scores[str(k)] = knn_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the table below, the top row 1, 11, 21, 31, 41 are the different k values, and left colums represent how each k perform on 10 different test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.923611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.951389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.965035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1        11        21        31        41\n",
       "0  0.979167  0.958333  0.958333  0.951389  0.930556\n",
       "1  0.979167  0.965278  0.958333  0.951389  0.944444\n",
       "2  0.993056  0.979167  0.979167  0.972222  0.965278\n",
       "3  0.993056  0.972222  0.958333  0.951389  0.923611\n",
       "4  1.000000  0.986111  0.979167  0.979167  0.951389\n",
       "5  0.993056  0.993056  0.986111  0.986111  0.986111\n",
       "6  1.000000  0.993056  0.993056  0.986111  0.979167\n",
       "7  0.979021  0.972028  0.965035  0.965035  0.965035\n",
       "8  0.979021  0.979021  0.965035  0.951049  0.930070\n",
       "9  0.986014  0.972028  0.951049  0.951049  0.930070"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.988156\n",
       "11    0.977030\n",
       "21    0.969362\n",
       "31    0.964491\n",
       "41    0.950573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can find that k=1 perform the best for the knn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on determining lable on test dataset is 98.61111111111111 %\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors = 1)    \n",
    "knn_clf.fit(X_train, y_train)      \n",
    "a=knn_clf.score(X_test,y_test)\n",
    "print(\"the accuracy on determining lable on test dataset is\", a*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
